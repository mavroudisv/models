- name: Generate signatures.json index
  run: |
    cat > generate_index.py << 'EOL'
import os
import json
import glob
import re
from datetime import datetime
from collections import defaultdict

# Find all model directories
model_dirs = glob.glob('signatures/*')
all_models = {}

for model_dir in sorted(model_dirs):
    model_name = os.path.basename(model_dir)
    signature_files = glob.glob(f'{model_dir}/*.json')
    
    if signature_files:
        # Sort by date in filename (most recent first)
        def get_date_from_filename(filename):
            match = re.search(r'_(\d{4}-\d{2}-\d{2})\.json$', filename)
            if match:
                return match.group(1)
            return '0000-00-00'
        
        # Sort all files by date
        sorted_files = sorted(signature_files, key=get_date_from_filename, reverse=True)
        
        # Create data for this model
        model_data = {
            'name': model_name,
            'signatures': []
        }
        
        for file_path in sorted_files:
            file_name = os.path.basename(file_path)
            date_match = re.search(r'_(\d{4}-\d{2}-\d{2})\.json$', file_name)
            file_date = date_match.group(1) if date_match else "Unknown"
            
            hash_match = re.search(r'^([^_]+)_', file_name)
            file_hash = hash_match.group(1) if hash_match else "Unknown"
            
            # Try to get full hash from file
            try:
                with open(file_path, 'r') as f:
                    data = json.load(f)
                file_full_hash = data.get('metadata', {}).get('distribution_hash', file_hash)
            except:
                file_full_hash = file_hash
            
            # Add to model data
            model_data['signatures'].append({
                'file': file_path,
                'date': file_date,
                'hash': file_hash,
                'full_hash': file_full_hash
            })
        
        # Add to all models
        all_models[model_name] = model_data

# Update the last_updated timestamp
metadata = {
    'last_updated': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
}

# Write to signatures.json
with open('signatures.json', 'w') as f:
    json.dump({
        'metadata': metadata,
        'models': all_models
    }, f, indent=2)
EOL
    
    # Run the update script
    python generate_index.py
    
- name: Commit and push new signatures
  run: |
    # Pull the latest changes first
    git pull --rebase origin main
    
    # Then check if there are changes to commit
    if [[ -n $(git status --porcelain signatures/ signatures.json) ]]; then
      git add signatures/ signatures.json
      git commit -m "Add new signature data [automated]"
      git push
    else
      echo "No new signature files to commit"
    fi
